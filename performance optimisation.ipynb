{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.57 s, sys: 4.61 s, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('data/tuef_master.txt') as fil:\n",
    "    dat = fil.read()\n",
    "dat = [i.split('\\\\t') for i in dat.split('\\n')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 0 ns, total: 1.03 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(dat[1:-1], columns = dat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    bgn = txt.find(\"TUEF\")\n",
    "    end = txt.find('0102**')+5+1\n",
    "    txt = txt[bgn:end]\n",
    "    length = int(txt[-17:].replace(\"ES07\", \"\")[:7])\n",
    "    return {\n",
    "        'string': txt,\n",
    "        'valid': len(txt[bgn: end]) == length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.96 s, sys: 124 ms, total: 4.09 s\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = pd.DataFrame([clean(i) for i in df.response_xml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635247, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635247"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reference_number.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parsed'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "db = MongoClient('mongodb://10.10.225.142:27017')['cibil']\n",
    "db.authenticate('nilabja21607', 'pass@123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 903 ms, sys: 85.2 ms, total: 988 ms\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.drop(\"response_xml\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload of raw string commenced:\n",
      "\n",
      "CPU times: user 26.9 s, sys: 3.2 s, total: 30.1 s███████████████████████████████████████████████████ Speed:7981.31 iter/sec\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import time\n",
    "start = time()\n",
    "print('Upload of raw string commenced:\\n')\n",
    "step = 5000\n",
    "tuef = df.to_dict(orient='record')\n",
    "for idx in range(0, len(tuef), step):\n",
    "    db['raw_upload'].insert_many(tuef[idx:idx+step])\n",
    "    perc = round(min((idx+step), len(tuef)) / len(tuef) * 100)\n",
    "    elapsed = time() - start\n",
    "    speed = \"{:.2f} iter/sec\".format(idx / elapsed) if idx > elapsed else \\\n",
    "        \"{:.2f} sec/iter\".format(elapsed/(idx+step))\n",
    "    print(\"{}{} Speed:{}\".format(u\"\\u2588\"*perc, u\"\\u2501\"*(100-perc), speed),\n",
    "          end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_chunk_breaker(string: str, splitter: str, shift: int = 2) -> list:\n",
    "    \"\"\" Compute ... and return ...\n",
    "    :return:\n",
    "    :param string:\n",
    "    :param splitter:\n",
    "    :param shift:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    chunk = string.split(splitter)\n",
    "    chunk.pop(0)\n",
    "    return [str_breaker(indx[shift:]) for indx in chunk]\n",
    "\n",
    "\n",
    "def str_breaker(string):\n",
    "    \"\"\"\n",
    "    :param string:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    while string:\n",
    "        key = string[:2]\n",
    "        string = string[2:]\n",
    "        length = int(string[:2])\n",
    "        string = string[2:]\n",
    "        val = string[:length]\n",
    "        string = string[length:]\n",
    "        ret[key] = val\n",
    "    return ret\n",
    "\n",
    "\n",
    "# the tuef contains several segments which have definite start values\n",
    "\n",
    "\n",
    "keymap = db['keymap'].find_one()\n",
    "\n",
    "pattern = re.compile(\n",
    "    \"(PN03N01|ID03I01|PT03T01|EC03C01|EM03E01|SC10CIBILTUSCR|PA03A01|\"\n",
    "    \"TL04T001|IQ04I001|DR03D01)\"\n",
    ")  # Create the pattern to break the tuef string into segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tuef(string):\n",
    "    tuef = string[:-17]\n",
    "    chunkdict = {}\n",
    "    breaks = [m.start() for m in pattern.finditer(tuef)]\n",
    "    breaks.insert(0, 0)\n",
    "    breaks.append(len(tuef))\n",
    "\n",
    "    for i in range(1, len(breaks)):\n",
    "        temp = tuef[breaks[i - 1]:breaks[i]]\n",
    "        chunkdict[temp[:2]] = temp\n",
    "\n",
    "    header = {}\n",
    "    header[\"seg_tag\"], tuef = tuef[:4], tuef[4:]\n",
    "    header[\"version\"], tuef = tuef[:2], tuef[2:]\n",
    "    header[\"mem_ref_no\"], tuef = tuef[:25].strip(), tuef[25:]\n",
    "    header[\"blank\"], tuef = tuef[:6], tuef[6:]\n",
    "    header[\"enq_mem_user_id\"], tuef = tuef[:30].strip(), tuef[30:]\n",
    "    header[\"sub_ret_cd\"], tuef = tuef[:1], tuef[1:]\n",
    "    header[\"enq_cntrl_no\"], tuef = tuef[:12], tuef[12:]\n",
    "    header[\"datetime_processed\"] = datetime.strptime(\n",
    "        tuef[:14], '%d%m%Y%H%M%S')\n",
    "    ######################################################################\n",
    "    #                                 PN decoding                        #\n",
    "    ######################################################################\n",
    "\n",
    "    name_chunk = chunkdict.get('PN')\n",
    "    if name_chunk:\n",
    "        name = str_breaker(name_chunk[7:])\n",
    "        name = {keymap['PN'][key]: val for key, val in name.items()}\n",
    "        if 'gender' in name:\n",
    "            name['gender'] = keymap['gender'][name['gender']]\n",
    "        if 'dob' in name:\n",
    "            name['dob'] = datetime.strptime(name['dob'], '%d%m%Y')\n",
    "        name = {key: val for key, val in name.items() if val is not None}\n",
    "        header.update(name)\n",
    "    ######################################################################\n",
    "    #                                 ID decoding                        #\n",
    "    ######################################################################\n",
    "\n",
    "    id_chunk = chunkdict.get('ID')\n",
    "    if id_chunk:\n",
    "        ids = pd.DataFrame(multi_chunk_breaker(id_chunk, \"ID03I\"))\n",
    "        ids.columns = [keymap['ID'][key] for key in ids.columns]\n",
    "        if \"id_type\" in ids:\n",
    "            ids[\"id_type\"] = [keymap[\"id_type\"][i] for i in\n",
    "                              ids[\"id_type\"]]\n",
    "        if \"issue_date\" in ids:\n",
    "            ids[\"issue_date\"] = pd.to_datetime(ids[\"issue_date\"],\n",
    "                                               format='%d%m%Y')\n",
    "        if \"expiration_date\" in ids:\n",
    "            ids[\"expiration_date\"] = pd.to_datetime(\n",
    "                ids[\"expiration_date\"], format='%d%m%Y')\n",
    "        header['ids'] = ids.T.apply(lambda x: x.dropna().to_dict()).\\\n",
    "            tolist()\n",
    "    ######################################################################\n",
    "    #                            PT decoding                             #\n",
    "    ######################################################################\n",
    "\n",
    "    phone_chunk = chunkdict.get('PT')\n",
    "    if phone_chunk:\n",
    "        tele = pd.DataFrame(multi_chunk_breaker(phone_chunk, \"PT03T\"))\n",
    "        tele.columns = [keymap['PT'][key] for key in tele.columns]\n",
    "        if \"telephone_type\" in tele:\n",
    "            tele[\"telephone_type\"] = [keymap[\"telephone_type\"][i] for i in\n",
    "                                      tele[\"telephone_type\"]]\n",
    "        header['phones'] = tele.T.apply(\n",
    "            lambda x: x.dropna().to_dict()).tolist()\n",
    "    ######################################################################\n",
    "    #                                 EC decoding                        #\n",
    "    ######################################################################\n",
    "\n",
    "    email_chunk = chunkdict.get('EC')\n",
    "    if email_chunk:\n",
    "        email = pd.DataFrame(multi_chunk_breaker(email_chunk, \"EC03C\"))\n",
    "        email.columns = ['email']\n",
    "        header['emails'] = \\\n",
    "            email.email.str.lower().dropna().unique().tolist()\n",
    "\n",
    "    ######################################################################\n",
    "    #                            EM decoding                             #\n",
    "    ######################################################################\n",
    "\n",
    "    employ_chunk = chunkdict.get('EM')\n",
    "    if employ_chunk:\n",
    "        employ = str_breaker(employ_chunk[7:])\n",
    "        employ = {keymap['EM'][key]: val for key, val in employ.items()}\n",
    "        employ['account_type'] = keymap['account_type'][\n",
    "            employ['account_type']]\n",
    "        employ['date_reported_and_certified'] = datetime.strptime(\n",
    "            employ['date_reported_and_certified'], '%d%m%Y')\n",
    "        employ['occupation_code'] = keymap['occupation_code'].get(\n",
    "            employ.get('occupation_code'))\n",
    "        employ['net_gross_income_indicator'] = \\\n",
    "            keymap['net_gross_income_indicator'].get(employ.get(\n",
    "                'net_gross_income_indicator'))\n",
    "        employ['monthly_annual_income_indicator'] = \\\n",
    "            keymap['monthly_annual_income_indicator'].get(\n",
    "                employ.get('monthly_annual_income_indicator'))\n",
    "        employ = {key: val for key, val in employ.items()\n",
    "                  if val is not None}\n",
    "        header.update(employ)\n",
    "    ######################################################################\n",
    "    #                       SC decoding                                  #\n",
    "    ######################################################################\n",
    "\n",
    "    score_chunk = chunkdict.get(\"SC\")\n",
    "    if score_chunk:\n",
    "        score = str_breaker(score_chunk[14:])\n",
    "        score = {keymap['SC'][key]: val for key, val in score.items()}\n",
    "        score['score_date'] = datetime.strptime(score['score_date'],\n",
    "                                                '%d%m%Y')\n",
    "        score = {key: val for key, val in score.items()\n",
    "                 if val is not None}\n",
    "        header.update(score)\n",
    "    ######################################################################\n",
    "    #                                 PA decoding                        #\n",
    "    ######################################################################\n",
    "\n",
    "    addr_chunk = chunkdict.get(\"PA\")\n",
    "    if addr_chunk:\n",
    "        addr = pd.DataFrame(multi_chunk_breaker(addr_chunk, \"PA03A\"))\n",
    "        addr.columns = [keymap['PA'][key] for key in addr.columns]\n",
    "        if 'date_reported' in addr:\n",
    "            addr['date_reported'] = pd.to_datetime(addr['date_reported'],\n",
    "                                                   format='%d%m%Y')\n",
    "        if 'state_code' in addr:\n",
    "            addr['state_code'] = [keymap['state_code'].get(i) for i in\n",
    "                                  addr['state_code']]\n",
    "        if 'address_category' in addr:\n",
    "            addr['address_category'] = [keymap['address_category'].get(i)\n",
    "                                    for i in addr['address_category']]\n",
    "        header['addresses'] = addr.T.apply(\n",
    "            lambda x: x.dropna().to_dict()).tolist()\n",
    "\n",
    "    ######################################################################\n",
    "    #                       TL decoding                                  #\n",
    "    ######################################################################\n",
    "\n",
    "    acc_chunk = chunkdict.get('TL')\n",
    "    if acc_chunk:\n",
    "        acc = multi_chunk_breaker(acc_chunk, \"TL04T\", 3)\n",
    "        summary = pd.DataFrame([i for i in acc if\n",
    "                                i['02'] == \"ACCTREVIEW_SUMM\"])\n",
    "        acc = pd.DataFrame([i for i in acc if i['02']\n",
    "                            != \"ACCTREVIEW_SUMM\"])\n",
    "        acc.columns = [keymap['TL'][key] for key in acc.columns]\n",
    "        summary.columns = [keymap['summary'][key] for\n",
    "                           key in summary.columns]\n",
    "        acc['account_name'] = [keymap['account_type'][i]['Name'] for i in\n",
    "                               acc['account_type']]\n",
    "        acc['account_type'] = [keymap['account_type'][i]['loan_type'] for i in\n",
    "                               acc['account_type']]\n",
    "        acc['ownership_indicator'] = [keymap['ownership_indicator'][i] for\n",
    "                                      i in acc['ownership_indicator']]\n",
    "        datecols = list({'date_opened_disbursed', 'date_of_last_payment',\n",
    "                         'date_closed', 'date_reported_certified',\n",
    "                         'payment_history_start_date',\n",
    "                         'payment_history_end_date'}.intersection(\n",
    "            acc.columns))\n",
    "        acc[datecols] = acc[datecols].apply(pd.to_datetime,\n",
    "                                            format=\"%d%m%Y\")\n",
    "        if 'suit_filed_wilful_default' in acc:\n",
    "            acc['suit_filed_wilful_default'] = \\\n",
    "                [keymap['suit_filed_wilful_default'].get(i) for i in\n",
    "                 acc['suit_filed_wilful_default']]\n",
    "        header['accounts'] = acc.T.apply(\n",
    "            lambda x: x.dropna().to_dict()).tolist()\n",
    "    ######################################################################\n",
    "    #                                 IQ decoding                        #\n",
    "    ######################################################################\n",
    "    enquiry_chunk = chunkdict.get('IQ')\n",
    "    if enquiry_chunk:\n",
    "        enq = pd.DataFrame(multi_chunk_breaker(enquiry_chunk, \"IQ04I\", 3))\n",
    "        enq.columns = [keymap['IQ'][key] for key in enq.columns]\n",
    "        enq['date_of_enquiry'] = pd.to_datetime(enq['date_of_enquiry'],\n",
    "                                                format='%d%m%Y')\n",
    "        enq['enquiry_purpose_acct_nm'] = [keymap['account_type'][i]['Name'] for i in\n",
    "                               enq['enquiry_purpose']]\n",
    "        enq['enquiry_purpose_acct_typ'] = [keymap['account_type'][i]['loan_type'] for i in\n",
    "                               enq['enquiry_purpose']]\n",
    "        header['enquiries'] = enq.T.apply(\n",
    "            lambda x: x.dropna().to_dict()).tolist()\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "to_parse = db['raw_upload'].find({\n",
    "    'parsed': False,\n",
    "    'valid': True\n",
    "}, {'string':1})\n",
    "try:\n",
    "    total = to_parse.count()\n",
    "except:\n",
    "    total = db['raw_upload'].count_documents({\n",
    "    'parsed': False,\n",
    "    'valid': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████████████████████████████████████████ Speed:32.90 iter/sec | ETA: 0:00:03\r"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "idx = 0\n",
    "output = []\n",
    "ids = []\n",
    "chunk = 100\n",
    "for i in to_parse:\n",
    "    try:\n",
    "        output.append(parse_tuef(i['string']))\n",
    "    except:\n",
    "        db['failed'].insert_one(i)\n",
    "    else:\n",
    "        ids.append(i['_id'])\n",
    "    idx += 1\n",
    "    if not idx % chunk:\n",
    "        db['parsed_tuef'].insert_many(output)\n",
    "        db['raw_upload'].update_many({\"_id\":{\"$in\": ids}}, {\"$set\":{\"parsed\":True}})\n",
    "        output = []\n",
    "        ids = []\n",
    "        perc = round(100 * idx / total)\n",
    "        elapsed = time() - start\n",
    "        speed = \"{:.2f} iter/sec\".format(idx / elapsed) if idx > elapsed else \\\n",
    "            \"{:.2f} sec/iter\".format(elapsed / (idx + args.chunk))\n",
    "        eta = str(timedelta(seconds = round(elapsed * (total-idx)/idx)))\n",
    "        print(\"{}{} Speed:{} | ETA: {}\".format(\n",
    "            u\"\\u2588\" * perc, u\"\\u2501\" * (100 - perc), speed, eta), end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
